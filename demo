#!/usr/bin/env python3
"""Helper script to launch a simplified demo of the low-latency stream kit."""
from __future__ import annotations

import argparse
import asyncio
import importlib.metadata
import importlib.util
import os
import shutil
import signal
import subprocess
import sys
import tempfile
import threading
import time
import socket
import shlex
from datetime import UTC, datetime
from pathlib import Path
from typing import Any, Dict, Iterable, List, Sequence, Tuple

from tspi_kit.commands import COMMAND_SUBJECT_PREFIX
from tspi_kit.datastore import MessageRecord, TagRecord
from tspi_kit.jetstream_client import normalize_stream_subjects

PROJECT_ROOT = Path(__file__).resolve().parent
APT_UPDATED = False


def parse_args(argv: List[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Run the JetStream demo setup.")
    parser.add_argument(
        "--duration",
        type=float,
        default=None,
        help="Optional duration (seconds) to run before shutting down. Defaults to running until interrupted.",
    )
    parser.add_argument(
        "--count",
        type=int,
        default=10,
        help="Number of simulated aircraft to generate.",
    )
    parser.add_argument(
        "--rate",
        type=float,
        default=20.0,
        help="Generation rate in Hertz for the simulator.",
    )
    parser.add_argument(
        "--log-dir",
        type=Path,
        default=None,
        help="Optional directory to store JetStream logs. Defaults to a temporary directory.",
    )
    return parser.parse_args(argv)


def ensure_python_version() -> None:
    if sys.version_info < (3, 11):
        raise RuntimeError("Python 3.11 or newer is required to run the demo helper script.")


def ensure_command(
    command: str,
    *,
    apt_package: str | None = None,
    brew_package: str | None = None,
) -> None:
    if shutil.which(command):
        return
    if apt_package and shutil.which("apt-get"):
        install_with_apt(apt_package)
        if shutil.which(command):
            return
    if brew_package and shutil.which("brew"):
        install_with_brew(brew_package)
        if shutil.which(command):
            return
    hints = []
    if apt_package:
        hints.append(f"`apt-get install {apt_package}`")
    if brew_package:
        hints.append(f"`brew install {brew_package}`")
    if hints:
        hint_message = " Install it via " + " or ".join(hints) + "."
    else:
        hint_message = ""
    raise RuntimeError(
        f"Required command '{command}' is not available on PATH.{hint_message}"
    )


def install_with_apt(package: str) -> None:
    global APT_UPDATED
    env = os.environ.copy()
    env.setdefault("DEBIAN_FRONTEND", "noninteractive")
    if not APT_UPDATED:
        subprocess.run(["apt-get", "update"], check=True, env=env, stdout=subprocess.DEVNULL)
        APT_UPDATED = True
    subprocess.run(["apt-get", "install", "-y", package], check=True, env=env)


def install_with_brew(package: str) -> None:
    subprocess.run(["brew", "install", package], check=True)


def read_requirements(path: Path) -> List[Tuple[str, str]]:
    requirements: List[Tuple[str, str]] = []
    for raw_line in path.read_text().splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#"):
            continue
        if raw_line.startswith(" ") or raw_line.startswith("\t"):
            continue
        requirement = line.split("#", 1)[0].strip()
        if not requirement:
            continue
        name = requirement
        for delimiter in ("==", ">=", "<=", "~=", ">", "<"):
            if delimiter in requirement:
                name = requirement.split(delimiter, 1)[0].strip()
                break
        requirements.append((name, requirement))
    return requirements


def ensure_python_dependencies(requirements_path: Path) -> None:
    missing: List[str] = []
    for name, requirement in read_requirements(requirements_path):
        try:
            installed_version = importlib.metadata.version(name)
        except importlib.metadata.PackageNotFoundError:
            missing.append(requirement)
            continue
        if "==" in requirement:
            expected = requirement.split("==", 1)[1].strip()
            if installed_version != expected:
                missing.append(requirement)
    if missing:
        print(f"Installing missing Python packages: {', '.join(missing)}")
        if importlib.util.find_spec("pip") is None:
            try:
                import ensurepip
            except ImportError as exc:  # pragma: no cover - defensive fallback
                raise RuntimeError(
                    "Python 'pip' module is not available and could not be bootstrapped."
                ) from exc
            ensurepip.bootstrap(upgrade=True)
        subprocess.check_call([sys.executable, "-m", "pip", "install", *missing])
    else:
        print("All required Python packages are already installed.")


class JetStreamServer:
    """Manage a single JetStream-enabled NATS server process."""

    def __init__(
        self,
        *,
        client_port: int = 4222,
        monitor_port: int = 8222,
        log_dir: Path | None = None,
    ) -> None:
        self.client_port = client_port
        self.monitor_port = monitor_port
        self._temp_dir_obj = tempfile.TemporaryDirectory() if log_dir is None else None
        self.base_dir = (Path(self._temp_dir_obj.name) if self._temp_dir_obj else log_dir).resolve()
        self.store_dir = self.base_dir / "store"
        self.logs_dir = self.base_dir / "logs"
        self.store_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        self._process: subprocess.Popen[str] | None = None
        self._log_handle: object | None = None

    @property
    def client_url(self) -> str:
        return f"nats://127.0.0.1:{self.client_port}"

    def _wait_for_port(self, timeout: float = 30.0) -> None:
        deadline = time.monotonic() + timeout
        while time.monotonic() < deadline:
            if self._process is not None and self._process.poll() not in (None, 0):
                raise RuntimeError("The JetStream server exited during startup. Check logs for details.")
            try:
                with socket.create_connection(("127.0.0.1", self.client_port), timeout=0.5):
                    return
            except OSError:
                time.sleep(0.2)
        raise RuntimeError(
            f"Timed out waiting for JetStream server to become ready on port {self.client_port}"
        )

    def start(self) -> None:
        if self._process is not None:
            return
        log_path = self.logs_dir / "server.log"
        log_handle = log_path.open("w")
        cmd = [
            "nats-server",
            "-js",
            "--store_dir",
            str(self.store_dir),
            "--port",
            str(self.client_port),
            "--http_port",
            str(self.monitor_port),
            "--name",
            "demo-server",
        ]
        self._process = subprocess.Popen(
            cmd,
            stdout=log_handle,
            stderr=subprocess.STDOUT,
            text=True,
        )
        self._log_handle = log_handle
        print(f"Started JetStream server. Logs at {log_path}")
        self._wait_for_port()

    def stop(self) -> None:
        if self._process is None:
            if self._temp_dir_obj is not None:
                self._temp_dir_obj.cleanup()
            return
        if self._process.poll() is None:
            self._process.terminate()
            try:
                self._process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                self._process.kill()
        if self._log_handle is not None:
            try:
                self._log_handle.close()  # type: ignore[call-arg]
            except Exception:
                pass
            self._log_handle = None
        self._process = None
        if self._temp_dir_obj is not None:
            self._temp_dir_obj.cleanup()
            self._temp_dir_obj = None


class InMemoryTimescaleStore:
    """Simple in-memory stand-in for the Timescale datastore used by the demo."""

    def __init__(self) -> None:
        self._messages: List[MessageRecord] = []
        self._message_ids: Dict[str, int] = {}
        self._commands: Dict[str, Dict[str, Any]] = {}
        self._tags: Dict[str, TagRecord] = {}
        self._next_id = 1
        self._lock = asyncio.Lock()

    async def connect(self) -> None:
        return None

    async def close(self) -> None:
        async with self._lock:
            self._messages.clear()
            self._message_ids.clear()
            self._commands.clear()
            self._tags.clear()
            self._next_id = 1

    async def insert_message(
        self,
        *,
        subject: str,
        kind: str,
        payload: Dict[str, Any],
        headers: Dict[str, Any],
        published_ts: datetime,
        raw_cbor: bytes,
    ) -> int | None:
        headers_dict = {str(key): str(value) for key, value in headers.items()}
        payload_dict = dict(payload)
        message_key = headers_dict.get("Nats-Msg-Id")
        async with self._lock:
            if message_key and message_key in self._message_ids:
                return None
            record_id = self._next_id
            self._next_id += 1
            record = MessageRecord(
                id=record_id,
                subject=subject,
                kind=kind,
                published_ts=self._to_timestamp(published_ts),
                headers=headers_dict,
                payload=payload_dict,
                cbor=bytes(raw_cbor),
                recv_epoch_ms=self._coerce_optional_int(payload_dict.get("recv_epoch_ms")),
                recv_iso=self._coerce_optional_iso(payload_dict.get("recv_iso")),
                message_type=self._coerce_optional_str(payload_dict.get("type")),
                sensor_id=self._coerce_optional_int(payload_dict.get("sensor_id")),
                day=self._coerce_optional_int(payload_dict.get("day")),
                time_s=self._coerce_optional_float(payload_dict.get("time_s")),
            )
            self._messages.append(record)
            if message_key:
                self._message_ids[message_key] = record_id
        return record_id

    async def fetch_messages_between(self, start_ts: float, end_ts: float) -> Sequence[MessageRecord]:
        async with self._lock:
            return [
                record
                for record in self._messages
                if start_ts <= record.published_ts <= end_ts
            ]

    async def fetch_messages_for_tag(self, tag_id: str, *, window_seconds: float = 10.0) -> Sequence[MessageRecord]:
        tag = await self.get_tag(tag_id)
        if tag is None:
            return []
        centre = self._to_datetime(tag.ts).timestamp()
        half_window = window_seconds / 2.0
        return await self.fetch_messages_between(centre - half_window, centre + half_window)

    async def upsert_command(
        self,
        payload: Dict[str, Any],
        *,
        message_id: int,
        published_ts: datetime,
    ) -> None:
        cmd_id = payload.get("cmd_id")
        if not cmd_id:
            return
        enriched = dict(payload)
        enriched.setdefault("message_id", message_id)
        enriched.setdefault("published_ts", self._to_datetime(published_ts).isoformat())
        key = str(cmd_id)
        async with self._lock:
            self._commands[key] = enriched

    async def latest_command(self, name: str) -> Dict[str, Any] | None:
        async with self._lock:
            candidates = [
                dict(record)
                for record in self._commands.values()
                if str(record.get("name")) == name
            ]
        if not candidates:
            return None
        return sorted(candidates, key=lambda record: record.get("published_ts", ""), reverse=True)[0]

    async def apply_tag_event(
        self,
        subject: str,
        payload: Dict[str, Any],
        *,
        message_id: int,
    ) -> None:
        tag_id = payload.get("id")
        if not tag_id:
            return
        async with self._lock:
            existing = self._tags.get(str(tag_id))
            base = existing.__dict__ if existing else {}
            ts_value = payload.get("ts", base.get("ts"))
            updated_ts_value = payload.get(
                "updated_ts", payload.get("ts", base.get("updated_ts"))
            )
            status = payload.get("status")
            if status is None:
                if subject.endswith(".delete"):
                    status = "deleted"
                else:
                    status = base.get("status", "active")
            extra_payload = payload.get("extra", base.get("extra", {}))
            if not isinstance(extra_payload, dict):
                extra_payload = {}
            record = TagRecord(
                id=str(tag_id),
                ts=self._coerce_iso(ts_value),
                creator=self._coerce_optional_str(payload.get("creator", base.get("creator"))),
                label=self._coerce_optional_str(payload.get("label", base.get("label"))),
                category=self._coerce_optional_str(payload.get("category", base.get("category"))),
                notes=self._coerce_optional_str(payload.get("notes", base.get("notes"))),
                extra=dict(extra_payload),
                status=str(status),
                updated_ts=self._coerce_iso(updated_ts_value),
            )
            self._tags[record.id] = record

    async def get_tag(self, tag_id: str) -> TagRecord | None:
        async with self._lock:
            return self._tags.get(tag_id)

    async def count_messages(self) -> int:
        async with self._lock:
            return len(self._messages)

    async def count_commands(self) -> int:
        async with self._lock:
            return len(self._commands)

    async def count_tags(self) -> int:
        async with self._lock:
            return len(self._tags)

    @staticmethod
    def _to_datetime(value: datetime | float | int | str) -> datetime:
        if isinstance(value, datetime):
            return value.astimezone(UTC) if value.tzinfo else value.replace(tzinfo=UTC)
        if isinstance(value, (float, int)):
            return datetime.fromtimestamp(float(value), tz=UTC)
        return datetime.fromisoformat(str(value)).astimezone(UTC)

    @classmethod
    def _to_timestamp(cls, value: datetime | float | int | str) -> float:
        return cls._to_datetime(value).timestamp()

    @classmethod
    def _coerce_iso(cls, value: object | None) -> str:
        if value is None:
            return cls._to_datetime(datetime.now(tz=UTC)).isoformat()
        if isinstance(value, datetime):
            return cls._to_datetime(value).isoformat()
        return str(value)

    @classmethod
    def _coerce_optional_iso(cls, value: object | None) -> str | None:
        if value is None:
            return None
        return cls._coerce_iso(value)

    @staticmethod
    def _coerce_optional_str(value: object | None) -> str | None:
        if value is None:
            return None
        return str(value)

    @staticmethod
    def _coerce_optional_int(value: object | None) -> int | None:
        if value is None:
            return None
        try:
            return int(value)
        except (TypeError, ValueError):
            return None

    @staticmethod
    def _coerce_optional_float(value: object | None) -> float | None:
        if value is None:
            return None
        try:
            return float(value)
        except (TypeError, ValueError):
            return None


def main(argv: Iterable[str] | None = None) -> int:
    args = parse_args(list(argv) if argv is not None else None)
    ensure_python_version()
    ensure_command(
        "nats-server",
        apt_package="nats-server",
        brew_package="nats-server",
    )
    requirements_path = PROJECT_ROOT / "requirements.txt"
    if requirements_path.exists():
        ensure_python_dependencies(requirements_path)
    else:
        print("requirements.txt not found; skipping Python dependency check.")

    from nats import errors as nats_errors
    from nats.aio.client import Client as NATS

    ErrNoServers = getattr(nats_errors, "ErrNoServers", nats_errors.NoServersError)
    NATSTimeoutError = getattr(
        nats_errors, "TimeoutError", getattr(nats_errors, "ErrTimeout", asyncio.TimeoutError)
    )

    from nats.js.errors import NotFoundError

    try:
        from nats.js.errors import BadRequestError
    except Exception:  # pragma: no cover - optional dependency mismatch
        BadRequestError = None  # type: ignore[assignment]

    try:
        from nats.js.errors import TimeoutError as JSNATSTimeoutError
    except Exception:  # pragma: no cover - optional dependency mismatch
        JSNATSTimeoutError = NATSTimeoutError  # type: ignore[assignment]
    from tspi_kit.archiver import Archiver

    async def connect_to_server(url: str) -> NATS:
        deadline = time.monotonic() + 60.0
        attempt = 0
        while True:
            attempt += 1
            nc = NATS()
            try:
                await nc.connect(
                    servers=[url],
                    connect_timeout=2,
                    max_reconnect_attempts=-1,
                    reconnect_time_wait=0.5,
                )
                print(f"Connected to JetStream server on attempt {attempt}.")
                return nc
            except ErrNoServers:
                if time.monotonic() >= deadline:
                    raise RuntimeError("Timed out waiting for JetStream server to become ready.")
                await asyncio.sleep(1.0)

    async def prepare_stream(js) -> None:
        stream_name = "TSPI"
        subjects = normalize_stream_subjects(["tspi.>", f"{COMMAND_SUBJECT_PREFIX}.>", "tags.>"])
        timeout_candidates: list[type[BaseException]] = []
        for candidate in (
            NATSTimeoutError,
            JSNATSTimeoutError,
            asyncio.TimeoutError,
            TimeoutError,
        ):
            if isinstance(candidate, type):
                timeout_candidates.append(candidate)
        timeout_exceptions = tuple(dict.fromkeys(timeout_candidates))

        deadline = time.monotonic() + 60.0
        last_info = None
        while True:
            try:
                try:
                    last_info = await js.stream_info(stream_name)
                except NotFoundError:
                    await js.add_stream(
                        name=stream_name,
                        subjects=subjects,
                        num_replicas=1,
                        retention="limits",
                        max_msgs=-1,
                        max_bytes=-1,
                    )
                    last_info = await js.stream_info(stream_name)
                else:
                    await js.update_stream(
                        {"name": stream_name, "subjects": subjects, "num_replicas": 1}
                    )
                    last_info = await js.stream_info(stream_name)
                break
            except timeout_exceptions as exc:
                if time.monotonic() >= deadline:
                    raise RuntimeError("Timed out preparing JetStream stream") from exc
                await asyncio.sleep(1.0)
            except Exception as exc:
                if BadRequestError is not None and isinstance(exc, BadRequestError):
                    err_code = getattr(exc, "err_code", None)
                    description = getattr(exc, "description", "")
                    if err_code == 10005 or "no suitable peers" in str(description).lower():
                        if time.monotonic() >= deadline:
                            raise RuntimeError("Timed out preparing JetStream stream") from exc
                        await asyncio.sleep(1.0)
                        continue
                raise
        for durable in ("demo-player", "demo-receiver"):
            try:
                await js.delete_consumer(stream_name, durable)
            except NotFoundError:
                continue

    async def run_async() -> None:
        server = JetStreamServer(log_dir=args.log_dir)
        datastore: InMemoryTimescaleStore | None = None
        archiver_task: asyncio.Task[None] | None = None
        generator_proc: subprocess.Popen[str] | None = None
        command_proc: subprocess.Popen[str] | None = None
        player_proc: subprocess.Popen[str] | None = None
        stop_event = threading.Event()
        shutdown_event = asyncio.Event()
        try:
            server.start()
            datastore = InMemoryTimescaleStore()
            await datastore.connect()
            print("Started in-memory datastore for demo use.")
            loop = asyncio.get_running_loop()
            nc: NATS | None = None
            try:
                nc = await connect_to_server(server.client_url)
                js = nc.jetstream()
                await prepare_stream(js)
                await asyncio.sleep(2.0)

                if datastore is None:
                    raise RuntimeError("Datastore failed to initialise")

                archiver = Archiver(js, datastore, durable_prefix="demo")

                async def archiver_worker() -> None:
                    try:
                        while not stop_event.is_set():
                            try:
                                stored = await archiver.drain()
                            except Exception as exc:  # pragma: no cover - diagnostics
                                print(f"[datastore] archiver error: {exc}", file=sys.stderr)
                                await asyncio.sleep(1.0)
                                continue
                            if stored:
                                total = await datastore.count_messages()
                                print(
                                    f"[datastore] persisted {stored} message(s) (total {total})",
                                    flush=True,
                                )
                            else:
                                await asyncio.sleep(0.5)
                    except asyncio.CancelledError:  # pragma: no cover - cancellation handling
                        raise

                archiver_task = asyncio.create_task(archiver_worker())

                qt_env = os.environ.copy()
                qt_env.pop("QT_QPA_PLATFORM", None)

                generator_cmd: List[str] = [
                    sys.executable,
                    str(PROJECT_ROOT / "tspi_generator_flet.py"),
                    "--count",
                    str(args.count),
                    "--rate",
                    str(args.rate),
                    "--duration",
                    "1.0",
                    "--continuous",
                    "--js-stream",
                    "TSPI",
                    "--stream-prefix",
                    "tspi",
                    "--nats-server",
                    server.client_url,
                ]

                player_cmd: List[str] = [
                    sys.executable,
                    str(PROJECT_ROOT / "player_flet.py"),
                    "--metrics-interval",
                    "1.0",
                    "--room",
                    "demo",
                    "--durable-prefix",
                    "demo",
                    "--js-stream",
                    "TSPI",
                    "--source",
                    "live",
                    "--nats-server",
                    server.client_url,
                ]

                command_cmd: List[str] = [
                    sys.executable,
                    str(PROJECT_ROOT / "command_console_flet.py"),
                    "--sender-id",
                    "demo-ui",
                    "--js-stream",
                    "TSPI",
                    "--ops-stream",
                    "TSPI_OPS",
                    "--stream-prefix",
                    "tspi",
                    "--nats-server",
                    server.client_url,
                ]

                try:
                    generator_proc = subprocess.Popen(generator_cmd, env=qt_env)
                    print(f"Launched generator UI: {shlex.join(generator_cmd)}", flush=True)
                except Exception as exc:
                    raise RuntimeError(f"Failed to launch generator UI: {exc}") from exc

                try:
                    player_proc = subprocess.Popen(player_cmd, env=qt_env)
                    print(f"Launched receiver UI: {shlex.join(player_cmd)}", flush=True)
                except Exception as exc:
                    if generator_proc is not None and generator_proc.poll() is None:
                        generator_proc.terminate()
                    if command_proc is not None and command_proc.poll() is None:
                        command_proc.terminate()
                    raise RuntimeError(f"Failed to launch receiver UI: {exc}") from exc

                try:
                    command_proc = subprocess.Popen(command_cmd, env=qt_env)
                    print(f"Launched command UI: {shlex.join(command_cmd)}", flush=True)
                except Exception as exc:
                    for proc in (player_proc, generator_proc):
                        if proc is not None and proc.poll() is None:
                            proc.terminate()
                    raise RuntimeError(f"Failed to launch command UI: {exc}") from exc

                async def monitor_process(name: str, proc: subprocess.Popen[str]) -> None:
                    await asyncio.to_thread(proc.wait)
                    if not shutdown_event.is_set():
                        print(f"{name} exited; shutting down demo.", flush=True)
                        request_shutdown()

                loop.create_task(monitor_process("Generator UI", generator_proc))
                loop.create_task(monitor_process("Receiver UI", player_proc))
                loop.create_task(monitor_process("Command UI", command_proc))

                def request_shutdown() -> None:
                    if not shutdown_event.is_set():
                        print("Shutdown requested. Cleaning up...", flush=True)
                        stop_event.set()
                        shutdown_event.set()

                for sig in (signal.SIGINT, signal.SIGTERM):
                    try:
                        loop.add_signal_handler(sig, request_shutdown)
                    except NotImplementedError:  # pragma: no cover - fallback for non-UNIX
                        signal.signal(sig, lambda _sig, _frame: request_shutdown())

                if args.duration is not None:
                    async def auto_stop() -> None:
                        await asyncio.sleep(max(0.1, args.duration))
                        request_shutdown()

                    loop.create_task(auto_stop())

                print("Demo environment is running. Press Ctrl+C to stop.")
                await shutdown_event.wait()
            finally:
                stop_event.set()
                for name, proc in (
                    ("generator UI", generator_proc),
                    ("receiver UI", player_proc),
                    ("command UI", command_proc),
                ):
                    if proc is None:
                        continue
                    if proc.poll() is None:
                        proc.terminate()
                        try:
                            proc.wait(timeout=10)
                        except subprocess.TimeoutExpired:
                            proc.kill()
                            try:
                                proc.wait(timeout=5)
                            except subprocess.TimeoutExpired:
                                pass
                    exit_code = proc.returncode
                    print(f"{name} exited with code {exit_code}.", flush=True)
                if archiver_task is not None:
                    archiver_task.cancel()
                    try:
                        await archiver_task
                    except asyncio.CancelledError:  # pragma: no cover - expected on shutdown
                        pass
                if datastore is not None:
                    total_messages = await datastore.count_messages()
                    total_commands = await datastore.count_commands()
                    total_tags = await datastore.count_tags()
                    print(
                        "Datastore summary: "
                        f"{total_messages} message(s), {total_commands} command(s), {total_tags} tag(s).",
                        flush=True,
                    )
                    await datastore.close()
                if nc is not None:
                    try:
                        await nc.drain()
                    finally:
                        await nc.close()
        finally:
            server.stop()

    try:
        asyncio.run(run_async())
    except KeyboardInterrupt:
        return 1
    except Exception as exc:
        print(f"Demo failed: {exc}", file=sys.stderr)
        return 1
    return 0


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(main())
